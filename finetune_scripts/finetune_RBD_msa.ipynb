{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8b3bbd-2c2f-4b11-a951-7bd397084979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 2999815it [01:15, 39969.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Path1) Use Lineage value from metadata to get Variant Label from voc.json file \n",
    "# voc.json file contains all the Lineage values that NCBI has classified under each VOC/VOI/VUM category and non VOC Lineage values\n",
    "\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths for input CSV and JSON files and output CSV file\n",
    "input_csv_path = '/your/path/to/filtered_msaCodon_1024_trimmed_RBD_3mil.csv'\n",
    "voc_json_path = '/your/path/to/voc.json'\n",
    "output_csv_path = '/your/path/to/filtered_msaCodon_1024_trimmed_RBD_3mil_with_LineageMappedVOC.csv'\n",
    "\n",
    "# Load the VOC data from JSON file\n",
    "with open(voc_json_path, 'r') as voc_file:\n",
    "    voc_data = json.load(voc_file)\n",
    "\n",
    "# Create a mapping of lineages to VOC labels\n",
    "lineage_to_voc = {}\n",
    "for voc_label, lineages in voc_data.items():\n",
    "    for lineage in lineages:\n",
    "        lineage_to_voc[lineage] = voc_label\n",
    "\n",
    "# Open input CSV for reading\n",
    "with open(input_csv_path, 'r') as input_file:\n",
    "    reader = csv.DictReader(input_file)\n",
    "\n",
    "    # Open output CSV for writing\n",
    "    with open(output_csv_path, 'w', newline='') as output_file:\n",
    "        # Get the fieldnames from the input CSV and add 'VOC_label' as a new field\n",
    "        fieldnames = reader.fieldnames + ['VOC_label']\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write header to output CSV\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Initialize tqdm for progress bar\n",
    "        for row in tqdm(reader, desc='Processing rows'):\n",
    "            # Get the lineage from the current row\n",
    "            lineage = row['Lineage']\n",
    "\n",
    "            # Determine the VOC_label for the lineage from lineage_to_voc mapping\n",
    "            voc_label = lineage_to_voc.get(lineage, 'Unknown')\n",
    "\n",
    "            # Add the VOC_label to the row data\n",
    "            row['VOC_label'] = voc_label\n",
    "\n",
    "            # Write the updated row to the output CSV\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ddaad4-a8b1-44fe-97d8-7a635bb64ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of label names to numeric values:\n",
      "sars_cov_2_delta: 0\n",
      "sars_cov_2_alpha: 1\n",
      "sars_cov_2_omicron: 2\n",
      "sars_cov_2_WuhanHu1: 3\n",
      "sars_cov_2_gamma: 4\n",
      "sars_cov_2_iota: 5\n",
      "sars_cov_2_mu: 6\n",
      "sars_cov_2_kappa: 7\n",
      "sars_cov_2_zeta: 8\n",
      "sars_cov_2_beta: 9\n",
      "sars_cov_2_epsilon: 10\n",
      "sars_cov_2_lambda: 11\n",
      "sars_cov_2_eta: 12\n",
      "sars_cov_2_theta: 13\n"
     ]
    }
   ],
   "source": [
    "# Path1) Use Lineage value from metadata to get Variant Label from voc.json file \n",
    "# Creating uniform variant label values from trimmed RBD dataset and mapping labels to numeric values\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def transform_csv(input_csv, output_csv):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Create the new 'label_name' column by prefixing 'sars_cov_2_' to the 'VOC' column\n",
    "    df['label_name'] = 'sars_cov_2_' + df['VOC_label']\n",
    "\n",
    "    # Remove rows where 'label_name' is 'sars_cov_2_nonVOC'\n",
    "    df = df[df['label_name'] != 'sars_cov_2_nonVOC']\n",
    "    df = df[df['label_name'] != 'sars_cov_2_Unknown']\n",
    "    # Create a mapping from unique 'label_name' to a numeric value\n",
    "    label_mapping = {label: idx for idx, label in enumerate(df['label_name'].unique())}\n",
    "\n",
    "    # Create the 'label_number' column by mapping 'label_name' to its corresponding numeric value\n",
    "    df['label_number'] = df['label_name'].map(label_mapping)\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={'Accession ID': 'EPI_ID', 'RBD nucleotide': 'sequence'})\n",
    "\n",
    "    # Select relevant columns and write them to the output CSV file\n",
    "    df[['EPI_ID', 'sequence', 'label_name', 'label_number']].to_csv(output_csv, index=False)\n",
    "\n",
    "    # Print the mapping of label names to numbers\n",
    "    print(\"Mapping of label names to numeric values:\")\n",
    "    for label, number in label_mapping.items():\n",
    "        print(f\"{label}: {number}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv_path = \"/your/path/to/filtered_msaCodon_1024_trimmed_RBD_3mil_with_LineageMappedVOC.csv\"\n",
    "    output_csv_path = \"/your/path/to/RBD_nucleotides_3mil_LineageMappedVOC_wo_nonvoc.csv\"\n",
    "    transform_csv(input_csv_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fce43ab-b4ee-475c-9599-99699bf91cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of label names to numeric values:\n",
      "sars_cov_2_delta: 0\n",
      "sars_cov_2_alpha: 1\n",
      "sars_cov_2_omicron: 2\n",
      "sars_cov_2_gamma: 3\n",
      "sars_cov_2_iota: 4\n",
      "sars_cov_2_mu: 5\n",
      "sars_cov_2_kappa: 6\n",
      "sars_cov_2_eta: 7\n",
      "sars_cov_2_beta: 8\n",
      "sars_cov_2_epsilon: 9\n",
      "sars_cov_2_lambda: 10\n"
     ]
    }
   ],
   "source": [
    "# Path2) Use Variant column value from metadata to extract Variant label (done in extract_RBD_from_MSA.ipynb script)\n",
    "# Creating uniform variant label values from trimmed RBD dataset and mapping labels to numeric values\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def transform_csv(input_csv, output_csv):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Create the new 'label_name' column by prefixing 'sars_cov_2_' to the 'VOC' column\n",
    "    df['label_name'] = 'sars_cov_2_' + df['Variant']\n",
    "\n",
    "    # Uncomment this line of script if you want to exclude 'sars_cov_2_nonVOC' labels from training dataset\n",
    "    #df = df[df['label_name'] != 'sars_cov_2_nonVOC']\n",
    "\n",
    "    # Create a mapping from unique 'label_name' to a numeric value\n",
    "    label_mapping = {label: idx for idx, label in enumerate(df['label_name'].unique())}\n",
    "\n",
    "    # Create the 'label_number' column by mapping 'label_name' to its corresponding numeric value\n",
    "    df['label_number'] = df['label_name'].map(label_mapping)\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={'Accession ID': 'EPI_ID', 'RBD nucleotide': 'sequence'})\n",
    "\n",
    "    # Select relevant columns and write them to the output CSV file\n",
    "    df[['EPI_ID', 'sequence', 'label_name', 'label_number']].to_csv(output_csv, index=False)\n",
    "\n",
    "    # Print the mapping of label names to numbers\n",
    "    print(\"Mapping of label names to numeric values:\")\n",
    "    for label, number in label_mapping.items():\n",
    "        print(f\"{label}: {number}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv_path = \"/your/path/to/filtered_msaCodon_1024_trimmed_RBD_3mil_with_VOC.csv\"\n",
    "    output_csv_path = \"/your/path/to/RBD_nucleotides_3mil_wt_nonvoc.csv\"\n",
    "    transform_csv(input_csv_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df85830a-5c0f-4b68-a41b-3c8aa723faba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for each Variant value:\n",
      "sars_cov_2_omicron: 1286237\n",
      "sars_cov_2_delta: 837496\n",
      "sars_cov_2_nonVOC: 456912\n",
      "sars_cov_2_alpha: 355994\n",
      "sars_cov_2_gamma: 28391\n",
      "sars_cov_2_iota: 11602\n",
      "sars_cov_2_epsilon: 10211\n",
      "sars_cov_2_beta: 4175\n",
      "sars_cov_2_eta: 3673\n",
      "sars_cov_2_mu: 3151\n",
      "sars_cov_2_lambda: 1302\n",
      "sars_cov_2_kappa: 671\n",
      "\n",
      "Total number of sequences: 2999815\n"
     ]
    }
   ],
   "source": [
    "# Generating counts for each variant label and total number of RBD sequences\n",
    "import pandas as pd\n",
    "rbd_df= pd.read_csv('/your/path/to/RBD_nucleotides_3mil_wt_nonvoc.csv')\n",
    "\n",
    "# Get the counts for each unique value in the 'Variant' column\n",
    "variant_counts = rbd_df['label_name'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts for each Variant value:\")\n",
    "for variant, count in variant_counts.items():\n",
    "    print(f\"{variant}: {count}\")\n",
    "    \n",
    "# Calculate the total number of entries in the 'Variant' column\n",
    "total_variants = rbd_df['label_name'].count()\n",
    "# Print the total number of entries\n",
    "print(f\"\\nTotal number of sequences: {total_variants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f9601f-764f-4a31-80f4-556e1ba79899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'N' found in the 'RBD nucleotide' column.\n"
     ]
    }
   ],
   "source": [
    "# Checking for ambigious nucleotides\n",
    "import pandas as pd\n",
    "rbd_df= pd.read_csv('/your/path/to/RBD_nucleotides_3mil_wt_nonvoc.csv')\n",
    "\n",
    "# Look for presence of ambigious nucleotide N in any sequence\n",
    "if rbd_df['sequence'].str.contains('N').any():\n",
    "    print(\"There is at least one 'N' in the 'RBD nucleotide' column.\")\n",
    "else:\n",
    "    print(\"No 'N' found in the 'RBD nucleotide' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b818ca23-75bc-4b86-be03-191d0a880961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the output CSV: 428391\n",
      "Variant: sars_cov_2_delta, Number of rows: 100000\n",
      "Variant: sars_cov_2_alpha, Number of rows: 100000\n",
      "Variant: sars_cov_2_omicron, Number of rows: 100000\n",
      "Variant: sars_cov_2_nonVOC, Number of rows: 100000\n",
      "Variant: sars_cov_2_gamma, Number of rows: 28391\n"
     ]
    }
   ],
   "source": [
    "# Creating subset of above output csv with desired number of unique EPI_IDs for each hCOV19 variant label\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def filter_and_write_csv(input_csv, output_csv, min_rows_per_variant=100000, max_rows_per_variant=100000):\n",
    "    # Initialize a dictionary to count the number of valid rows per variant\n",
    "    variant_counts = defaultdict(int)\n",
    "    variant_valid_rows = defaultdict(list)\n",
    "\n",
    "    with open(input_csv, 'r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            sequence = row['sequence'].upper()\n",
    "\n",
    "            # Check if the sequence contains only A, T, G, C\n",
    "            if set(sequence) <= {'A', 'T', 'G', 'C'}:\n",
    "                variant = row['label_name']\n",
    "                variant_valid_rows[variant].append(row)\n",
    "\n",
    "    # Filter out variants that do not have at least min_rows_per_variant valid rows\n",
    "    valid_variants = {variant: rows for variant, rows in variant_valid_rows.items() if len(rows) >= min_rows_per_variant}\n",
    "\n",
    "    # Write to output CSV\n",
    "    with open(output_csv, 'w', newline='') as outfile:\n",
    "        fieldnames = ['EPI_ID', 'label_name', 'label_number', 'sequence']\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        total_rows = 0\n",
    "        for variant, rows in valid_variants.items():\n",
    "            # Write only max_rows_per_variant rows for each variant\n",
    "            for row in rows[:max_rows_per_variant]:\n",
    "                writer.writerow(row)\n",
    "                variant_counts[variant] += 1\n",
    "                total_rows += 1\n",
    "\n",
    "    print(f\"Total number of rows in the output CSV: {total_rows}\")\n",
    "    for variant, count in variant_counts.items():\n",
    "        print(f\"Variant: {variant}, Number of rows: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv_path = \"/your/path/to/RBD_nucleotides_3mil_wt_nonvoc.csv\"\n",
    "    output_csv_path = \"/your/path/to/RBD_nucleotides_3mil_wt_nonvoc_100k_epi.csv\"\n",
    "    filter_and_write_csv(input_csv_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5d93676-b2eb-4a9b-94fd-4e34d7f14ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d319f4fe-c591-486c-b0d1-39318648303d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 428391/428391 [01:41<00:00, 4230.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMers and their reverse complements extracted and written to /mmfs1/projects/changhui.yan/DeewanB/DNABert2_rnaseq/genome_files/unfiltered_multiple_genomes/RBD_nucleotides_3mil_wt_nonvoc_100k_epi_250bp_50overlap_complementary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating 250bps fragments with 50 bp overlaps from RBD segments generated above\n",
    "# Generating reverse complementary sequence for each generated fragment \n",
    " \n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from Bio.Seq import Seq  # Import Seq class for reverse complement\n",
    "\n",
    "# Main directory path\n",
    "main_dir = \"/path/to/virus/finetune/csv/\"\n",
    "\n",
    "# Path to the input and output CSV files\n",
    "input_csv_path = \"/your/path/to/RBD_nucleotides_3mil_wt_nonvoc_100k_epi.csv\"\n",
    "output_csv_path = os.path.join(main_dir, \"RBD_nucleotides_3mil_wt_nonvoc_100k_epi_250bp_50overlap_complementary.csv\")\n",
    "\n",
    "# Read the input CSV file\n",
    "data = pd.read_csv(input_csv_path, low_memory=False)\n",
    "\n",
    "# Define the length of kmer and sliding window\n",
    "kmer_length = 250\n",
    "sliding_window = 50 \n",
    "\n",
    "def extract_kmers(sequence, kmer_length, sliding_window):\n",
    "    \"\"\"Extract kmers with a specified sliding window from the given sequence.\"\"\"\n",
    "    kmers = []\n",
    "    for start in range(0, len(sequence) - kmer_length + 1, sliding_window):\n",
    "        kmer = sequence[start:start + kmer_length]\n",
    "        kmers.append(kmer)\n",
    "    return kmers\n",
    "\n",
    "# Open the output CSV file for writing\n",
    "with open(output_csv_path, mode='w', newline='') as csv_file:\n",
    "    # Define the fieldnames for the output CSV\n",
    "    fieldnames = data.columns.tolist()\n",
    "    if 'sequence' in fieldnames:\n",
    "        fieldnames.remove('sequence')  # remove 'sequence' to add kmers later\n",
    "    fieldnames.append('sequence')\n",
    "    \n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Process each row in the input data with a progress bar\n",
    "    for _, row in tqdm(data.iterrows(), total=data.shape[0], desc='Processing Rows'):\n",
    "        sequence = row['sequence']\n",
    "        kmers = extract_kmers(sequence, kmer_length, sliding_window)\n",
    "        \n",
    "        # Write each kmer and its reverse complement with the associated row data\n",
    "        for kmer in kmers:\n",
    "            row_data = row.to_dict()  # Convert row to dictionary\n",
    "            row_data['sequence'] = kmer\n",
    "            writer.writerow(row_data)  # Write the original kmer\n",
    "            \n",
    "            # Generate and write the reverse complementary kmer\n",
    "            reverse_complementary_kmer = str(Seq(kmer).reverse_complement())\n",
    "            row_data['sequence'] = reverse_complementary_kmer\n",
    "            writer.writerow(row_data)  # Write the reverse complementary kmer\n",
    "\n",
    "print(f\"KMers and their reverse complements extracted and written to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "543da99c-5f6f-4587-bb8d-c1b964c7c82f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for each Variant value:\n",
      "sars_cov_2_delta: 1800000\n",
      "sars_cov_2_alpha: 1800000\n",
      "sars_cov_2_omicron: 1800000\n",
      "sars_cov_2_nonVOC: 1800000\n",
      "sars_cov_2_gamma: 511038\n",
      "\n",
      "Total number of sequences: 7711038\n"
     ]
    }
   ],
   "source": [
    "# Generating counts for each variant label and total number of RBD sequences\n",
    "import pandas as pd\n",
    "rbd_df= pd.read_csv('/your/path/to/RBD_nucleotides_3mil_wt_nonvoc_100k_epi_250bp_50overlap_complementary.csv')\n",
    "\n",
    "# Get the counts for each unique value in the 'Variant' column\n",
    "variant_counts = rbd_df['label_name'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts for each Variant value:\")\n",
    "for variant, count in variant_counts.items():\n",
    "    print(f\"{variant}: {count}\")\n",
    "    \n",
    "# Calculate the total number of entries in the 'Variant' column\n",
    "total_variants = rbd_df['label_name'].count()\n",
    "# Print the total number of entries\n",
    "print(f\"\\nTotal number of sequences: {total_variants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6d1058-dc4c-4071-936a-80b4cb2905a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Name: sars_cov_2_alpha\n",
      "  - Unique Label Numbers: [1]\n",
      "  - Number of Unique EPI_IDs: 100000\n",
      "----------------------------------------\n",
      "Label Name: sars_cov_2_delta\n",
      "  - Unique Label Numbers: [0]\n",
      "  - Number of Unique EPI_IDs: 100000\n",
      "----------------------------------------\n",
      "Label Name: sars_cov_2_gamma\n",
      "  - Unique Label Numbers: [3]\n",
      "  - Number of Unique EPI_IDs: 28391\n",
      "----------------------------------------\n",
      "Label Name: sars_cov_2_omicron\n",
      "  - Unique Label Numbers: [2]\n",
      "  - Number of Unique EPI_IDs: 100000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Checking to see if label_names are correctly mapped to label_numbers\n",
    "import pandas as pd\n",
    "\n",
    "def check_label_numbers_and_count_epi_ids(input_csv):\n",
    "    \"\"\"\n",
    "    Check the label_number values for each unique label_name value and print the number of EPI_ID values for each label_name.\n",
    "    \"\"\"\n",
    "    # Load the input CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Group by label_name and analyze label_number and EPI_ID counts\n",
    "    grouped = df.groupby('label_name')\n",
    "\n",
    "    for label_name, group in grouped:\n",
    "        unique_label_numbers = group['label_number'].unique()\n",
    "        epi_id_count = group['EPI_ID'].nunique()  # Count unique EPI_ID values\n",
    "\n",
    "        print(f\"Label Name: {label_name}\")\n",
    "        print(f\"  - Unique Label Numbers: {unique_label_numbers}\")\n",
    "        print(f\"  - Number of Unique EPI_IDs: {epi_id_count}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "input_csv = \"/your/path/to/RBD_nucleotides_3mil_wo_nonvoc_100k_epi_250bp_50overlap_complementary.csv\"\n",
    "# Run the function\n",
    "check_label_numbers_and_count_epi_ids(input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d602f-2a7d-4194-ae38-0583ed10551b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.3.0",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

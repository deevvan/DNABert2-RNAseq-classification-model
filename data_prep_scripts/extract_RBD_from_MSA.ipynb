{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24a89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting position of RBD in GISAID ref genome (with gaps): 22567\n",
      "Ending position of RBD in GISAID ref genome (with gaps): 23235\n"
     ]
    }
   ],
   "source": [
    "### Open Reading Frame for ncbi reference sequence RBD from https://www.ncbi.nlm.nih.gov/gene/1489668:\n",
    "\n",
    "################################################\n",
    "# Start sequence of RBD in NCBI: AGGGTTGTTCCCTCA\n",
    "# End sequence of RBD in NCBI: CCAGTGTGTCAATTTT\n",
    "\n",
    "# FROM MSA between GISAID ref genome and NCBI ref genome \n",
    "# Start sequence of RBD in GISAID: AGAGTCCAACCAACAG\n",
    "# End sequence of RBD in GISAID: CAAATGTGTCAATTTC\n",
    "################################################\n",
    "\n",
    "# NOTE: Since ORF indices for RBD belongs to NCBI ref genome, it needs to be converted to that for \n",
    "# GISAID ref genome since MSA file is based on that. So, to do that, the two ref genomes were aligned \n",
    "# using MUSCLE: https://www.ebi.ac.uk/Tools/msa/muscle/\n",
    "# With this MSA, and start and end sites for RBD being 22407 and 23072 in NCBI reference genome, \n",
    "# the position of these two sites were obtained from the MSA file below:\n",
    "\n",
    "def find_positions_RBD_in_GISAID_msa(msa_fasta_file):\n",
    "    with open(msa_fasta_file, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Combine the lines to form a single sequence.\n",
    "    sequence = \"\".join([line.strip() for line in lines[1:]])  # Skip the header line.\n",
    "\n",
    "    # Initialize counters for non-gap and total characters, and positions.\n",
    "    non_gap_count = 0\n",
    "    total_count = 0\n",
    "    position_RBD_start = None\n",
    "    position_RBD_end = None\n",
    "\n",
    "    # Iterate through the sequence to find the positions and count characters.\n",
    "    for i, char in enumerate(sequence):\n",
    "        total_count += 1\n",
    "        if char != \"-\":\n",
    "            non_gap_count += 1\n",
    "            if non_gap_count == 22407:\n",
    "                position_RBD_start = i + 1  # Adjust for 1-based indexing.\n",
    "            if non_gap_count == 23072:\n",
    "                position_RBD_end = i + 1\n",
    "\n",
    "    if position_RBD_start is not None and position_RBD_end is not None:\n",
    "        print(\"Starting position of RBD in GISAID ref genome (with gaps):\", position_RBD_start)\n",
    "        print(\"Ending position of RBD in GISAID ref genome (with gaps):\", position_RBD_end)\n",
    "\n",
    "def main():\n",
    "    msa_fasta_file = \"your/path/MUSCLE_MSA_refGenomes.fasta\"  # Change this to the actual file path.\n",
    "    find_positions_RBD_in_GISAID_msa(msa_fasta_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e8f581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position of RBD start site in MSA between NCBI and GISAID (including gaps): 22567\n",
      "Position of RBD stop site in MSA between NCBI and GISAID (including gaps): 23235\n",
      "Position of RBD start site in GISAID  without gaps: 22517\n",
      "Position of RBD stop site in GISAID without gaps: 23185\n"
     ]
    }
   ],
   "source": [
    "## After the start and stop sites for RBD in MSA between the two ref genomes were obtained, the gap characters \n",
    "## were removed from the GISAID ref genome to identify the position of the start and stop sites of RBD below:\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "def count_and_find_positions(msa_file):\n",
    "    # Read the MSA FASTA file\n",
    "    records = list(SeqIO.parse(msa_file, \"fasta\"))\n",
    "\n",
    "    # Check if the file has at least two sequences\n",
    "    if len(records) < 2:\n",
    "        print(\"Error: MSA file should contain at least two sequences.\")\n",
    "        return\n",
    "\n",
    "    # Extract the second sequence\n",
    "    sequence = str(records[1].seq)\n",
    "\n",
    "    # Count characters at positions 22567 and 23235 (including gaps)\n",
    "    count_at_22567 = sequence.count('-', 0, 22566) + sequence[0:22567].count('A') + sequence[0:22567].count('T') + sequence[0:22567].count('G') + sequence[0:22567].count('C')\n",
    "    count_at_23235 = sequence.count('-', 0, 23234) + sequence[0:23235].count('A') + sequence[0:23235].count('T') + sequence[0:23235].count('G') + sequence[0:23235].count('C')\n",
    "\n",
    "    print(f\"Position of RBD start site in MSA between NCBI and GISAID (including gaps): {count_at_22567}\")\n",
    "    print(f\"Position of RBD stop site in MSA between NCBI and GISAID (including gaps): {count_at_23235}\")\n",
    "\n",
    "    # Find the positions of characters without gaps\n",
    "    pos_22567_no_gaps = count_at_22567 - sequence[0:22567].count('-')\n",
    "    pos_23235_no_gaps = count_at_23235 - sequence[0:23235].count('-')\n",
    "\n",
    "    print(f\"Position of RBD start site in GISAID  without gaps: {pos_22567_no_gaps}\")\n",
    "    print(f\"Position of RBD stop site in GISAID without gaps: {pos_23235_no_gaps}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide the path to your MSA FASTA file\n",
    "    msa_file_path = \"your/path/MUSCLE_MSA_refGenomes.fasta\"\n",
    "    \n",
    "    count_and_find_positions(msa_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ef9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RBD extraction from GISAID MSA file here onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54afe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting position of RBD in GISAID ref genome (with gaps): 35011\n",
      "Ending position of RBD in GISAID ref genome (with gaps): 36610\n"
     ]
    }
   ],
   "source": [
    "# Python script identifies the start and end sites for RBD in reference genome when gaps are added for the\n",
    "# GISAID MSA sequences by counting nucleotides (A,T,G or C) only and ignoring gap character in \"-\" and then \n",
    "# counting these positions after gaps are added to get the actual location for these two \n",
    "# positions when gap is present\n",
    "\n",
    "### Open Reading Frame for RBD from https://www.ncbi.nlm.nih.gov/gene/1489668:\n",
    "\n",
    "##########################################################\n",
    "\n",
    "## Start position of RBD in GISAID reference genome: 22517\n",
    "## End position of RBD in GISAID reference genome: 23187 (2 NT ADDED TO MAKE MULTIPLE OF 3)\n",
    "\n",
    "def find_positions_RBD_in_msa_fasta(msa_fasta_file):\n",
    "    with open(msa_fasta_file, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Combine the lines to form a single sequence.\n",
    "    sequence = \"\".join([line.strip() for line in lines[1:]])  # Skip the header line.\n",
    "\n",
    "    # Initialize counters for non-gap and total characters, and positions.\n",
    "    non_gap_count = 0\n",
    "    total_count = 0\n",
    "    position_RBD_start = None\n",
    "    position_RBD_end = None\n",
    "\n",
    "    # Iterate through the sequence to find the positions and count characters.\n",
    "    for i, char in enumerate(sequence):\n",
    "        total_count += 1\n",
    "        if char != \"-\":\n",
    "            non_gap_count += 1\n",
    "            if non_gap_count == 22517:\n",
    "                position_RBD_start = i + 1  # Adjust for 1-based indexing.\n",
    "            if non_gap_count == 23187:\n",
    "                position_RBD_end = i + 1\n",
    "\n",
    "    if position_RBD_start is not None and position_RBD_end is not None:\n",
    "        print(\"Starting position of RBD in GISAID ref genome (with gaps):\", position_RBD_start)\n",
    "        print(\"Ending position of RBD in GISAID ref genome (with gaps):\", position_RBD_end)\n",
    "\n",
    "def main():\n",
    "    msa_fasta_file = \"your/path/ref_genome_MSA.fasta\"  # Change this to the actual file path.\n",
    "    find_positions_RBD_in_msa_fasta(msa_fasta_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:  68%|██████▊   | 10352067/15129074 [7:18:14<3:21:20, 395.44it/s]"
     ]
    }
   ],
   "source": [
    "# Python script to cleave the rest of the MSA sequences at the position corresponding \n",
    "# to spike RBD sequence in reference sequence after adding the gaps:\n",
    "\n",
    "########################################################################\n",
    "# RBD Start Position (22517 in ref genome) in MSA with gaps: 35011           \n",
    "# RBD End Ending Position (23187 in ref genome) in MSA with gaps: 36610\n",
    "\n",
    "######################### WORKING SCRIPT ###############################\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def trim_and_write_sequences(input_fasta, output_fasta, start_position, end_position):\n",
    "    # Count the number of sequences for progress tracking\n",
    "    with open(input_fasta, \"r\") as infile:\n",
    "        num_sequences = sum(1 for line in infile if line.startswith(\">\"))\n",
    "\n",
    "    with open(input_fasta, \"r\") as infile, open(output_fasta, \"w\") as outfile:\n",
    "        current_sequence = \"\"\n",
    "        current_header = \"\"\n",
    "\n",
    "        for line in tqdm(infile, total=num_sequences, desc=\"Processing sequences\"):\n",
    "            if line.startswith(\">\"):\n",
    "                # Write the previous sequence immediately after trimming\n",
    "                if current_sequence:\n",
    "                    # Convert the sequence to a tensor\n",
    "                    sequence_tensor = torch.tensor([ord(c) for c in current_sequence], dtype=torch.int32, device='cuda')\n",
    "                    # Trim and replace \"-\" with \"\"\n",
    "                    trimmed_sequence_tensor = sequence_tensor[start_position - 1:end_position]\n",
    "                    trimmed_sequence = ''.join(chr(c) for c in trimmed_sequence_tensor.cpu().numpy() if chr(c) != \"-\")\n",
    "                    outfile.write(f\"{current_header}\\n{trimmed_sequence}\\n\")\n",
    "\n",
    "                # Update current header for the next sequence\n",
    "                current_header = line.strip()\n",
    "                current_sequence = \"\"\n",
    "            else:\n",
    "                # Accumulate the sequence\n",
    "                current_sequence += line.strip()\n",
    "\n",
    "        # Trim and write the last sequence\n",
    "        if current_sequence:\n",
    "            sequence_tensor = torch.tensor([ord(c) for c in current_sequence], dtype=torch.int32, device='cuda')\n",
    "            trimmed_sequence_tensor = sequence_tensor[start_position - 1:end_position]\n",
    "            trimmed_sequence = ''.join(chr(c) for c in trimmed_sequence_tensor.cpu().numpy() if chr(c) != \"-\")\n",
    "            outfile.write(f\"{current_header}\\n{trimmed_sequence}\\n\")\n",
    "\n",
    "    print(f\"Trimmed sequences between positions {start_position} and {end_position} to '{output_fasta}'.\")\n",
    "\n",
    "def main():\n",
    "    input_fasta = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/msaCodon_0522.fasta\"\n",
    "    output_fasta = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/msaCodon_0522_trimmed_RBD.fasta\"\n",
    "    start_position = 35011\n",
    "    end_position = 36610\n",
    "\n",
    "    trim_and_write_sequences(input_fasta, output_fasta, start_position, end_position)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1cad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Statistics:\n",
      "Total Sequences: 15129074\n",
      "Total Bases: 9590532564\n",
      "Minimum Length: 0 bases\n",
      "Maximum Length: 714 bases\n",
      "Average Length: 633.91 bases\n"
     ]
    }
   ],
   "source": [
    "# Counting sequence statistics for trimmed RBD fasta file to find out if outliers exist\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "def generate_sequence_statistics(fasta_file):\n",
    "    sequence_lengths = []\n",
    "    total_sequences = 0\n",
    "    total_bases = 0\n",
    "\n",
    "    with open(fasta_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            total_sequences += 1\n",
    "            sequence_length = len(record.seq)\n",
    "            sequence_lengths.append(sequence_length)\n",
    "            total_bases += sequence_length\n",
    "\n",
    "    # Calculate statistics\n",
    "    min_length = min(sequence_lengths)\n",
    "    max_length = max(sequence_lengths)\n",
    "    average_length = total_bases / total_sequences\n",
    "\n",
    "    # Print the statistics\n",
    "    print(\"Sequence Statistics:\")\n",
    "    print(f\"Total Sequences: {total_sequences}\")\n",
    "    print(f\"Total Bases: {total_bases}\")\n",
    "    print(f\"Minimum Length: {min_length} bases\")\n",
    "    print(f\"Maximum Length: {max_length} bases\")\n",
    "    print(f\"Average Length: {average_length:.2f} bases\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fasta_file = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/msaCodon_0522_trimmed_RBD.fasta\"  # Replace with your FASTA file\n",
    "    generate_sequence_statistics(fasta_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255f694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences between lengths 634 and 634 written to '/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_0522_trimmed_RBD.fasta'.\n"
     ]
    }
   ],
   "source": [
    "# Calculate first quartile (Q1), third quartile (Q3), and the interquartile range (IQR) and \n",
    "# use the IQR to determine the lower and upper bounds for outlier detection and remove outlier readlengths.\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_sequence_lengths(fasta_file):\n",
    "    sequence_lengths = []\n",
    "    sequences = []\n",
    "\n",
    "    with open(fasta_file, \"r\") as file:\n",
    "        sequence = \"\"\n",
    "        header = \"\"\n",
    "\n",
    "        for line in file:\n",
    "            if line.startswith(\">\"):\n",
    "                if sequence:\n",
    "                    sequence_lengths.append(len(sequence))\n",
    "                    sequences.append((header, sequence))\n",
    "                header = line.strip()\n",
    "                sequence = \"\"\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "\n",
    "        # Don't forget to count the last sequence\n",
    "        if sequence:\n",
    "            sequence_lengths.append(len(sequence))\n",
    "            sequences.append((header, sequence))\n",
    "\n",
    "    return sequence_lengths, sequences\n",
    "\n",
    "def calculate_iqr_outliers(sequence_lengths):\n",
    "    q1 = np.percentile(sequence_lengths, 25)\n",
    "    q3 = np.percentile(sequence_lengths, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def filter_outliers_and_write(sequences, lower_bound, upper_bound, output_file):\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for header, sequence in sequences:\n",
    "            if lower_bound <= len(sequence) <= upper_bound:\n",
    "                outfile.write(f\"{header}\\n{sequence}\\n\")\n",
    "\n",
    "def main():\n",
    "    fasta_file = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/msaCodon_0522_trimmed_RBD.fasta\"\n",
    "    output_file = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_0522_trimmed_RBD.fasta\"\n",
    "\n",
    "    sequence_lengths, sequences = count_sequence_lengths(fasta_file)\n",
    "    lower_bound, upper_bound = calculate_iqr_outliers(sequence_lengths)\n",
    "    filter_outliers_and_write(sequences, lower_bound, upper_bound, output_file)\n",
    "\n",
    "    print(f\"Sequences between lengths {int(lower_bound)} and {int(upper_bound)} written to '{output_file}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8218760-8592-4c36-a210-ab491c023321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Statistics:\n",
      "Total Sequences: 14931769\n",
      "Total Bases: 9466741546\n",
      "Minimum Length: 634 bases\n",
      "Maximum Length: 634 bases\n",
      "Average Length: 634.00 bases\n"
     ]
    }
   ],
   "source": [
    "# Counting sequence statistics for filtered trimmed RBD fasta file to find out if outliers exist\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "def generate_sequence_statistics(fasta_file):\n",
    "    sequence_lengths = []\n",
    "    total_sequences = 0\n",
    "    total_bases = 0\n",
    "\n",
    "    with open(fasta_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            total_sequences += 1\n",
    "            sequence_length = len(record.seq)\n",
    "            sequence_lengths.append(sequence_length)\n",
    "            total_bases += sequence_length\n",
    "\n",
    "    # Calculate statistics\n",
    "    min_length = min(sequence_lengths)\n",
    "    max_length = max(sequence_lengths)\n",
    "    average_length = total_bases / total_sequences\n",
    "\n",
    "    # Print the statistics\n",
    "    print(\"Sequence Statistics:\")\n",
    "    print(f\"Total Sequences: {total_sequences}\")\n",
    "    print(f\"Total Bases: {total_bases}\")\n",
    "    print(f\"Minimum Length: {min_length} bases\")\n",
    "    print(f\"Maximum Length: {max_length} bases\")\n",
    "    print(f\"Average Length: {average_length:.2f} bases\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fasta_file = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_0522_trimmed_RBD.fasta\"  # Replace with your FASTA file\n",
    "    generate_sequence_statistics(fasta_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1075e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 14900000 valid sequences and saved to /mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.fasta\n"
     ]
    }
   ],
   "source": [
    "## Python script to make a subset of the filtered_msaCodon_1024_trimmed_RBD.fasta without N and  \n",
    "## also make sure length of each sequence is multiple of 3 \n",
    "\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "\n",
    "# Input FASTA file and output file\n",
    "input_fasta = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_0522_trimmed_RBD.fasta\"\n",
    "output_fasta = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.fasta\"\n",
    "\n",
    "# Read all sequences from the input FASTA file\n",
    "all_sequences = list(SeqIO.parse(input_fasta, \"fasta\"))\n",
    "\n",
    "# Randomly select 1 million sequences\n",
    "num_sequences_to_select = 14900000\n",
    "subset_sequences = random.sample(all_sequences, min(num_sequences_to_select, len(all_sequences)))\n",
    "\n",
    "# Filter sequences to contain only A, T, G, and C, and have lengths as multiples of 3\n",
    "valid_sequences = [seq for seq in subset_sequences if set(str(seq.seq)).issubset(\"ATGC\")]\n",
    "\n",
    "# Ensure each selected sequence length is a multiple of 3 or remove 1 or 2 nucleotides\n",
    "for i in range(len(valid_sequences)):\n",
    "    seq_len = len(valid_sequences[i])\n",
    "    if seq_len % 3 != 0:\n",
    "        trim_length = seq_len % 3\n",
    "        valid_sequences[i] = valid_sequences[i][:-trim_length]\n",
    "\n",
    "# Write the selected sequences to the output FASTA file\n",
    "with open(output_fasta, \"w\") as output_handle:\n",
    "    SeqIO.write(valid_sequences, output_handle, \"fasta\")\n",
    "\n",
    "print(f\"Randomly selected {num_sequences_to_select} valid sequences and saved to {output_fasta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f866d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|██████████| 12027544/12027544 [33:04<00:00, 6059.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output CSV file saved as /mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.csv\n"
     ]
    }
   ],
   "source": [
    "# Script to write out matching fasta files with Accession ID values in metadata file to csv files with Variant and Lineage values\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count, Manager\n",
    "\n",
    "# Load your metadata DataFrame and prepare it for lookups\n",
    "csv_file = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/metadata_2024_09_05.tsv\"\n",
    "df_metadata = pd.read_csv(csv_file, sep='\\t', dtype=str, low_memory=False, encoding='latin-1')\n",
    "\n",
    "# Convert metadata DataFrame to a dictionary for fast access by Accession ID\n",
    "metadata_dict = df_metadata.set_index('Accession ID')[['Pango lineage', 'Variant']].to_dict(orient='index')\n",
    "\n",
    "# Define the output CSV file\n",
    "output_csv_file = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.csv\"\n",
    "\n",
    "# Function to process each sequence\n",
    "def process_sequence(record):\n",
    "    accession_id_fasta = record.description.split(\"|\")[1]\n",
    "    sequence = str(record.seq)\n",
    "\n",
    "    # Check if the Accession ID is present in the metadata dictionary\n",
    "    if accession_id_fasta in metadata_dict:\n",
    "        metadata = metadata_dict[accession_id_fasta]\n",
    "        lineage = metadata['Pango lineage']\n",
    "        variant = metadata['Variant']\n",
    "\n",
    "        # Create a dictionary for the current record\n",
    "        return {\n",
    "            'Accession ID': accession_id_fasta,\n",
    "            'Lineage': lineage,\n",
    "            'RBD nucleotide': sequence,\n",
    "            'Variant': variant\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Function to handle batch writing to CSV\n",
    "def write_results_to_csv(output_csv_file, queue):\n",
    "    with open(output_csv_file, 'w', newline='') as f:\n",
    "        writer = pd.DataFrame(columns=['Accession ID', 'Lineage', 'RBD nucleotide', 'Variant'])\n",
    "        writer.to_csv(f, index=False)\n",
    "\n",
    "    # Batch size for writing to CSV\n",
    "    batch_size = 1000\n",
    "    batch = []\n",
    "    \n",
    "    while True:\n",
    "        result = queue.get()\n",
    "        if result == 'DONE':\n",
    "            break\n",
    "        batch.append(result)\n",
    "        \n",
    "        if len(batch) >= batch_size:\n",
    "            df = pd.DataFrame(batch)\n",
    "            df.to_csv(output_csv_file, mode='a', header=False, index=False)\n",
    "            batch.clear()\n",
    "\n",
    "    # Write any remaining records\n",
    "    if batch:\n",
    "        df = pd.DataFrame(batch)\n",
    "        df.to_csv(output_csv_file, mode='a', header=False, index=False)\n",
    "\n",
    "# Main function to handle multiprocessing\n",
    "def main():\n",
    "    fasta_file = \"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.fasta\"\n",
    "    \n",
    "    # Estimate the total number of sequences for tqdm\n",
    "    with open(fasta_file, \"r\") as fasta_file_handle:\n",
    "        total_sequences_estimated = sum(1 for line in fasta_file_handle if line.startswith(\">\"))\n",
    "\n",
    "    # Manager to handle a shared queue for multiprocessing\n",
    "    manager = Manager()\n",
    "    result_queue = manager.Queue()\n",
    "\n",
    "    # Start the writer process\n",
    "    writer_process = Pool(processes=1)\n",
    "    writer_process.apply_async(write_results_to_csv, (output_csv_file, result_queue))\n",
    "\n",
    "    # Use multiprocessing pool to process sequences in parallel\n",
    "    with Pool(processes=cpu_count()) as pool, tqdm(total=total_sequences_estimated, desc=\"Processing sequences\") as pbar:\n",
    "        for result in pool.imap(process_sequence, SeqIO.parse(fasta_file, \"fasta\")):\n",
    "            pbar.update()\n",
    "            if result:\n",
    "                result_queue.put(result)\n",
    "\n",
    "    # Signal the writer process to stop\n",
    "    result_queue.put('DONE')\n",
    "    writer_process.close()\n",
    "    writer_process.join()\n",
    "\n",
    "    print(f\"Output CSV file saved as {output_csv_file}\")\n",
    "\n",
    "# Execute the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81fa6452-136a-40da-82af-da9f3f7448af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rbd_csv = pd.read_csv(\"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee11d425-99f4-4e2d-a3c9-b0bc74de9b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accession ID</th>\n",
       "      <th>Lineage</th>\n",
       "      <th>RBD nucleotide</th>\n",
       "      <th>Variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPI_ISL_10839200</td>\n",
       "      <td>BA.1.15</td>\n",
       "      <td>ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...</td>\n",
       "      <td>Former VOC Omicron GRA (B.1.1.529+BA.*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPI_ISL_5652980</td>\n",
       "      <td>P.1.11</td>\n",
       "      <td>ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...</td>\n",
       "      <td>Former VOC Gamma GR/501Y.V3 (P.1+P.1.*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EPI_ISL_17397934</td>\n",
       "      <td>XBB.1.9.2</td>\n",
       "      <td>ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...</td>\n",
       "      <td>VUM GRA (XBB.1.9.2+XBB1.9.2.*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPI_ISL_9443030</td>\n",
       "      <td>BA.1</td>\n",
       "      <td>ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...</td>\n",
       "      <td>Former VOC Omicron GRA (B.1.1.529+BA.*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPI_ISL_4353158</td>\n",
       "      <td>AY.4</td>\n",
       "      <td>ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...</td>\n",
       "      <td>Former VOC Delta GK (B.1.617.2+AY.*)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accession ID    Lineage  \\\n",
       "0  EPI_ISL_10839200    BA.1.15   \n",
       "1   EPI_ISL_5652980     P.1.11   \n",
       "2  EPI_ISL_17397934  XBB.1.9.2   \n",
       "3   EPI_ISL_9443030       BA.1   \n",
       "4   EPI_ISL_4353158       AY.4   \n",
       "\n",
       "                                      RBD nucleotide  \\\n",
       "0  ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...   \n",
       "1  ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...   \n",
       "2  ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...   \n",
       "3  ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...   \n",
       "4  ACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACT...   \n",
       "\n",
       "                                   Variant  \n",
       "0  Former VOC Omicron GRA (B.1.1.529+BA.*)  \n",
       "1  Former VOC Gamma GR/501Y.V3 (P.1+P.1.*)  \n",
       "2           VUM GRA (XBB.1.9.2+XBB1.9.2.*)  \n",
       "3  Former VOC Omicron GRA (B.1.1.529+BA.*)  \n",
       "4     Former VOC Delta GK (B.1.617.2+AY.*)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbd_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121c7d76-f704-4da5-9619-8dcc48479fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Former VOC Omicron GRA (B.1.1.529+BA.*)'\n",
      " 'Former VOC Gamma GR/501Y.V3 (P.1+P.1.*)'\n",
      " 'VUM GRA (XBB.1.9.2+XBB1.9.2.*)' 'Former VOC Delta GK (B.1.617.2+AY.*)'\n",
      " 'Former VOC Alpha GRY (B.1.1.7+Q.*)' nan\n",
      " 'VUM GRA (XBB.1.9.1+XBB.1.9.1.*)' 'VOI GRA (XBB.1.5+XBB.1.5.*)'\n",
      " 'VOI GRA (EG.5+EG.5.*)' 'VUM GRA (CH.1.1+CH.1.1.*)'\n",
      " 'VOI GRA (XBB.1.16+XBB.1.16.*)'\n",
      " 'Former VOI Lambda GR/452Q.V1 (C.37+C.37.1)'\n",
      " 'VUM GRA (BA.2.75+BA.2.75.*)' 'Former VOI Zeta GR/484K.V2 (P.2)'\n",
      " 'VUM GRA (XBB.2.3+XBB.2.3.*)'\n",
      " 'Former VOI Epsilon GH/452R.V1 (B.1.429+B.1.427)'\n",
      " 'Former VOI Kappa G/452R.V3 (B.1.617.1)'\n",
      " 'VUM GRA (XBB+XBB.* excluding XBB.1.5, XBB.1.16, XBB.1.9.1, XBB.1.9.2, XBB.2.3)'\n",
      " 'Former VOC Beta GH/501Y.V2 (B.1.351+B.1.351.2+B.1.351.3)'\n",
      " 'Former VOI Mu GH (B.1.621+B.1.621.1)'\n",
      " 'Former VOI Eta G/484K.V3 (B.1.525)' 'VOI GRA (JN.1+JN.1.*)'\n",
      " 'Former VOI Iota GH/253G.V1 (B.1.526)'\n",
      " 'Former VUM GH/490R (B.1.640+B.1.640.*)'\n",
      " 'VOI GRA (BA.2.86+BA.2.86.* excluding JN.1, JN.1.*)'\n",
      " 'Former VOI Theta GR/1092K.V1 (P.3)']\n"
     ]
    }
   ],
   "source": [
    "# Remove everything after the closing parenthesis \")\" in each value of the 'Variant' column\n",
    "rbd_csv['Variant'] = rbd_csv['Variant'].str.split(')').str[0] + ')'\n",
    "\n",
    "# Access the 'Variant' column\n",
    "unique_Variant = rbd_csv['Variant'].unique()\n",
    "\n",
    "# Print the unique values in the 'Variant' column\n",
    "print(unique_Variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f16a7c4a-1531-4174-b988-d7ba738a510f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant\n",
      "Former VOC Omicron GRA (B.1.1.529+BA.*)                                           4979165\n",
      "Former VOC Delta GK (B.1.617.2+AY.*)                                              3888578\n",
      "Former VOC Alpha GRY (B.1.1.7+Q.*)                                                1043401\n",
      "VOI GRA (XBB.1.5+XBB.1.5.*)                                                        292598\n",
      "VOI GRA (EG.5+EG.5.*)                                                              167378\n",
      "Former VOC Gamma GR/501Y.V3 (P.1+P.1.*)                                            113831\n",
      "VOI GRA (XBB.1.16+XBB.1.16.*)                                                       92813\n",
      "VUM GRA (BA.2.75+BA.2.75.*)                                                         86212\n",
      "VUM GRA (XBB.1.9.1+XBB.1.9.1.*)                                                     77582\n",
      "VUM GRA (XBB+XBB.* excluding XBB.1.5, XBB.1.16, XBB.1.9.1, XBB.1.9.2, XBB.2.3)      70754\n",
      "Former VOI Epsilon GH/452R.V1 (B.1.429+B.1.427)                                     58365\n",
      "VUM GRA (CH.1.1+CH.1.1.*)                                                           52689\n",
      "VUM GRA (XBB.2.3+XBB.2.3.*)                                                         38412\n",
      "Former VOI Iota GH/253G.V1 (B.1.526)                                                37878\n",
      "VUM GRA (XBB.1.9.2+XBB1.9.2.*)                                                      30116\n",
      "Former VOC Beta GH/501Y.V2 (B.1.351+B.1.351.2+B.1.351.3)                            14825\n",
      "Former VOI Mu GH (B.1.621+B.1.621.1)                                                11307\n",
      "Former VOI Lambda GR/452Q.V1 (C.37+C.37.1)                                           9169\n",
      "Former VOI Eta G/484K.V3 (B.1.525)                                                   7079\n",
      "Former VOI Zeta GR/484K.V2 (P.2)                                                     6188\n",
      "VOI GRA (JN.1+JN.1.*)                                                                4277\n",
      "Former VOI Kappa G/452R.V3 (B.1.617.1)                                               3594\n",
      "Former VUM GH/490R (B.1.640+B.1.640.*)                                                805\n",
      "VOI GRA (BA.2.86+BA.2.86.* excluding JN.1, JN.1.*)                                    207\n",
      "Former VOI Theta GR/1092K.V1 (P.3)                                                     85\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the value counts for the 'Variant' column\n",
    "variant_counts = rbd_csv['Variant'].value_counts()\n",
    "\n",
    "# Print the counts of each unique 'Variant'\n",
    "print(variant_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af0ad057-d3e4-49d6-83eb-17547d655c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant\n",
      "Former VOC Omicron GRA (B.1.1.529+BA.*)                                           4979165\n",
      "Former VOC Delta GK (B.1.617.2+AY.*)                                              3888578\n",
      "Former VOC Alpha GRY (B.1.1.7+Q.*)                                                1043401\n",
      "VOI Omicron-subtype GRA (XBB.1.5+XBB.1.5.*)                                        292598\n",
      "VOI Eris GRA (EG.5+EG.5.*)                                                         167378\n",
      "Former VOC Gamma GR/501Y.V3 (P.1+P.1.*)                                            113831\n",
      "VOI Omicron-subtype GRA (XBB.1.16+XBB.1.16.*)                                       92813\n",
      "VUM Omicron GRA (BA.2.75+BA.2.75.*)                                                 86212\n",
      "VUM GRA (XBB.1.9.1+XBB.1.9.1.*)                                                     77582\n",
      "VUM GRA (XBB+XBB.* excluding XBB.1.5, XBB.1.16, XBB.1.9.1, XBB.1.9.2, XBB.2.3)      70754\n",
      "Former VOI Epsilon GH/452R.V1 (B.1.429+B.1.427)                                     58365\n",
      "VUM GRA (CH.1.1+CH.1.1.*)                                                           52689\n",
      "VUM GRA (XBB.2.3+XBB.2.3.*)                                                         38412\n",
      "Former VOI Iota GH/253G.V1 (B.1.526)                                                37878\n",
      "VUM GRA (XBB.1.9.2+XBB1.9.2.*)                                                      30116\n",
      "Former VOC Beta GH/501Y.V2 (B.1.351+B.1.351.2+B.1.351.3)                            14825\n",
      "Former VOI Mu GH (B.1.621+B.1.621.1)                                                11307\n",
      "Former VOI Lambda GR/452Q.V1 (C.37+C.37.1)                                           9169\n",
      "Former VOI Eta G/484K.V3 (B.1.525)                                                   7079\n",
      "Former VOI Zeta GR/484K.V2 (P.2)                                                     6188\n",
      "VOI FLiRT GRA (JN.1+JN.1.*)                                                          4277\n",
      "Former VOI Kappa G/452R.V3 (B.1.617.1)                                               3594\n",
      "Former VUM GH/490R (B.1.640+B.1.640.*)                                                805\n",
      "VOI GRA (BA.2.86+BA.2.86.* excluding JN.1, JN.1.*)                                    207\n",
      "Former VOI Theta GR/1092K.V1 (P.3)                                                     85\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "#rbd_csv = pd.read_csv(\"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.csv\")\n",
    "\n",
    "# Dictionary to map old Variant values to new Variant values\n",
    "variant_replacements = {\n",
    "    \"VOI GRA (XBB.1.5+XBB.1.5.*)\": \"VOI Omicron-subtype GRA (XBB.1.5+XBB.1.5.*)\",\n",
    "    \"VOI GRA (EG.5+EG.5.*)\": \"VOI Eris GRA (EG.5+EG.5.*)\",\n",
    "    \"VOI GRA (XBB.1.16+XBB.1.16.*)\": \"VOI Omicron-subtype GRA (XBB.1.16+XBB.1.16.*)\",\n",
    "    \"VUM GRA (BA.2.75+BA.2.75.*)\": \"VUM Omicron-subtype GRA (BA.2.75+BA.2.75.*)\",\n",
    "    \"VOI GRA (JN.1+JN.1.*)\": \"VOI FLiRT GRA (JN.1+JN.1.*)\"\n",
    "}\n",
    "\n",
    "# Replace the values in the 'Variant' column based on the dictionary\n",
    "rbd_csv['Variant'] = rbd_csv['Variant'].replace(variant_replacements)\n",
    "\n",
    "# Get the value counts for the 'Variant' column\n",
    "variant_counts = rbd_csv['Variant'].value_counts()\n",
    "\n",
    "# Print the counts of each unique 'Variant'\n",
    "print(variant_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae964063-e52f-46af-a62f-f1491ec1a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC\n",
      "Omicron    5450788\n",
      "Delta      3888578\n",
      "Alpha      1043401\n",
      "nonVOC      940219\n",
      "VUM_GRA     269553\n",
      "Eris        167378\n",
      "Gamma       113831\n",
      "Epsilon      58365\n",
      "Iota         37878\n",
      "Beta         14825\n",
      "Mu           11307\n",
      "Lambda        9169\n",
      "Eta           7079\n",
      "Zeta          6188\n",
      "FLiRT         4277\n",
      "Kappa         3594\n",
      "VUM_GH         805\n",
      "VOI_GRA        207\n",
      "Theta           85\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "#rbd_csv = pd.read_csv(\"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.csv\")\n",
    "\n",
    "# Define the mapping of keywords to VOC values\n",
    "variant_to_voc = {\n",
    "    \"Former VOC Omicron GRA\": \"Omicron\",\n",
    "    \"Former VOC Delta GK\": \"Delta\",\n",
    "    \"Former VOC Alpha GRY\": \"Alpha\",\n",
    "    \"VOI Omicron-subtype GRA\": \"Omicron\",\n",
    "    \"VUM GRA\": \"VUM_GRA\",\n",
    "    \"VOI Eris GRA\": \"Eris\",\n",
    "    \"Former VOC Gamma GR/501Y.V3\": \"Gamma\",\n",
    "    \"VUM Omicron GRA\": \"Omicron\",\n",
    "    \"Former VOI Epsilon GH/452R.V1\": \"Epsilon\",\n",
    "    \"Former VOI Iota GH/253G.V1\": \"Iota\",\n",
    "    \"Former VOC Beta GH/501Y.V2\": \"Beta\",\n",
    "    \"Former VOI Mu GH\": \"Mu\",\n",
    "    \"Former VOI Lambda GR/452Q.V1\": \"Lambda\",\n",
    "    \"Former VOI Eta G/484K.V3\": \"Eta\",\n",
    "    \"Former VOI Zeta GR/484K.V2\": \"Zeta\",\n",
    "    \"VOI FLiRT GRA\": \"FLiRT\",\n",
    "    \"Former VOI Kappa G/452R.V3\": \"Kappa\",\n",
    "    \"Former VUM GH/490R\": \"VUM_GH\",\n",
    "    \"VOI GRA\": \"VOI_GRA\",\n",
    "    \"Former VOI Theta GR/1092K.V1\": \"Theta\"\n",
    "}\n",
    "\n",
    "# Function to map the Variant to VOC\n",
    "def map_variant_to_voc(variant):\n",
    "    if pd.isna(variant):\n",
    "        return \"nonVOC\"\n",
    "    for key in variant_to_voc:\n",
    "        if key in variant:\n",
    "            return variant_to_voc[key]\n",
    "    return \"nonVOC\"\n",
    "\n",
    "# Ensure the Variant column is treated as a string\n",
    "rbd_csv['Variant'] = rbd_csv['Variant'].astype(str)\n",
    "\n",
    "# Apply the function to the Variant column and create the VOC column\n",
    "rbd_csv['VOC'] = rbd_csv['Variant'].apply(map_variant_to_voc)\n",
    "\n",
    "# Get the value counts for the 'VOC' column\n",
    "voc_counts = rbd_csv['VOC'].value_counts()\n",
    "\n",
    "# Print the counts of each unique VOC\n",
    "print(voc_counts)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file if needed\n",
    "rbd_csv.to_csv(\"/mmfs1/projects/changhui.yan/DeewanB/recent_hcov19_MSA/msaCodon_0522/filtered_msaCodon_1024_trimmed_RBD_15mil.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e430f5-3aed-4777-bd92-776db6b63096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cccd0be-624a-4cd2-9829-45d47622af27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefd7b6-de4e-453b-98bd-ba933f010fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.3.0",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd767a81-2095-404d-a224-de865f44a3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sars_cov_2_omicron: 177091 sequences\n",
      "sars_cov_2_delta: 173300 sequences\n",
      "sars_cov_2_nonvoc: 77063 sequences\n",
      "sars_cov_2_alpha: 49234 sequences\n",
      "sars_cov_2_wuhanhu1: 19990 sequences\n",
      "sars_cov_2_gamma: 5692 sequences\n",
      "sars_cov_2_epsilon: 2327 sequences\n",
      "sars_cov_2_iota: 2318 sequences\n",
      "sars_cov_2_beta: 952 sequences\n",
      "sars_cov_2_mu: 626 sequences\n",
      "sars_cov_2_lambda: 340 sequences\n",
      "sars_cov_2_zeta: 301 sequences\n",
      "sars_cov_2_eta: 283 sequences\n",
      "sars_cov_2_kappa: 59 sequences\n",
      "sars_cov_2_theta: 3 sequences\n"
     ]
    }
   ],
   "source": [
    "# Convert the variant values in input csv into label_name values and label_number values:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define function to get variant label\n",
    "def get_variant_label(variant):\n",
    "    return f'sars_cov_2_{variant.lower()}'\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_path = \"RBD_valid_nucleotides_500k_VOC.csv\"\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Apply the variant label function to the 'Variant' column\n",
    "df['label_name'] = df['variant'].apply(get_variant_label)\n",
    "\n",
    "# Assign each row a unique number\n",
    "df['EPI_ID'] = range(1, len(df) + 1)\n",
    "\n",
    "# Convert label names to numerical labels\n",
    "label_name_to_number = {name: idx for idx, name in enumerate(df['label_name'].unique())}\n",
    "df['label_number'] = df['label_name'].map(label_name_to_number)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_csv_path = \"spike_sequences_0709_VOC_labeled.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Print out the number of sequences belonging to each unique label_name value\n",
    "label_counts = df['label_name'].value_counts()\n",
    "for label_name, count in label_counts.items():\n",
    "    print(f\"{label_name}: {count} sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cccfa98-5b40-4c97-8e09-c568810a3129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bb945-4891-4333-9399-c7fc3b9bab9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76f3685-f000-486e-a58a-b96234e93d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of EPI_ID values for each label_name before filtering:\n",
      "label_name\n",
      "sars_cov_2_omicron     177091\n",
      "sars_cov_2_delta       173300\n",
      "sars_cov_2_nonvoc       77063\n",
      "sars_cov_2_alpha        49234\n",
      "sars_cov_2_wuhanhu1     19990\n",
      "sars_cov_2_gamma         5692\n",
      "sars_cov_2_epsilon       2327\n",
      "sars_cov_2_iota          2318\n",
      "sars_cov_2_beta           952\n",
      "sars_cov_2_mu             626\n",
      "sars_cov_2_lambda         340\n",
      "sars_cov_2_zeta           301\n",
      "sars_cov_2_eta            283\n",
      "sars_cov_2_kappa           59\n",
      "sars_cov_2_theta            3\n",
      "Name: count, dtype: int64\n",
      "Number of EPI_ID values for each label_name after filtering:\n",
      "label_name\n",
      "sars_cov_2_alpha       5000\n",
      "sars_cov_2_delta       5000\n",
      "sars_cov_2_gamma       5000\n",
      "sars_cov_2_nonvoc      5000\n",
      "sars_cov_2_omicron     5000\n",
      "sars_cov_2_wuhanhu1    5000\n",
      "Name: count, dtype: int64\n",
      "Filtered data written to RBD_valid_nucleotides_500k_VOC_labeled_5000_epi.csv\n"
     ]
    }
   ],
   "source": [
    "# python script that creates a subset that contains 900 sequences for each label_name value in the csv from above\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the paths\n",
    "input_csv_path = \"RBD_valid_nucleotides_500k_VOC_labeled.csv\"\n",
    "output_csv_path = \"RBD_valid_nucleotides_500k_VOC_labeled_5000_epi.csv\"\n",
    "\n",
    "# Read the input CSV file\n",
    "data = pd.read_csv(input_csv_path, low_memory=False)\n",
    "\n",
    "# Print the number of EPI_ID values for each label_name\n",
    "label_counts = data['label_name'].value_counts()\n",
    "print(\"Number of EPI_ID values for each label_name before filtering:\")\n",
    "print(label_counts)\n",
    "\n",
    "# Drop rows with label_name values that have less than 900 EPI_ID values\n",
    "filtered_data = data[data['label_name'].map(data['label_name'].value_counts()) >= 5000]\n",
    "\n",
    "# Remove rows where 'label_name' is 'sars_cov_2_nonvoc'\n",
    "#filtered_data = filtered_data[filtered_data['label_name'] != 'sars_cov_2_nonvoc']\n",
    "\n",
    "# Define an empty DataFrame to store the filtered results\n",
    "final_filtered_data = pd.DataFrame()\n",
    "\n",
    "# Group by 'label_name' and select up to 900 unique 'EPI_ID' values for each label\n",
    "for label_name, group in filtered_data.groupby('label_name'):\n",
    "    # Get up to 900 unique EPI_ID values for the current label_name\n",
    "    unique_epi_ids = group['EPI_ID'].unique()[:5000]\n",
    "    \n",
    "    # Filter the group to include only rows with the selected unique EPI_ID values\n",
    "    filtered_group = group[group['EPI_ID'].isin(unique_epi_ids)]\n",
    "    \n",
    "    # Append the filtered group to the final_filtered_data DataFrame\n",
    "    final_filtered_data = pd.concat([final_filtered_data, filtered_group])\n",
    "\n",
    "# Write the filtered data to the new CSV file\n",
    "final_filtered_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Print the number of EPI_ID values for each label_name after filtering\n",
    "filtered_label_counts = final_filtered_data['label_name'].value_counts()\n",
    "print(\"Number of EPI_ID values for each label_name after filtering:\")\n",
    "print(filtered_label_counts)\n",
    "\n",
    "print(f\"Filtered data written to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a1885-96c3-4af9-9273-d9b7c28c6645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977c37e9-52f4-40e5-b869-25d3cb995a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 509579/509579 [46:25<00:00, 182.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMers extracted and written to /mmfs1/projects/changhui.yan/DeewanB/DNABert2_rnaseq/genome_files/unfiltered_multiple_genomes/RBD_valid_nucleotides_500k_VOC_labeled_250bp_1bp_overlap.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# creating overlapping 250bps fragments with labels for sarscov2 RBD fragments\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Prompt user for the main directory path\n",
    "main_dir = \"/mmfs1/projects/changhui.yan/DeewanB/DNABert2_rnaseq/genome_files/unfiltered_multiple_genomes/\"\n",
    "\n",
    "# Path to the input and output CSV files\n",
    "input_csv_path = os.path.join(\"RBD_valid_nucleotides_500k_VOC_labeled.csv\")\n",
    "output_csv_path = os.path.join(main_dir, \"RBD_valid_nucleotides_500k_VOC_labeled_250bp_1bp_overlap.csv\")\n",
    "\n",
    "# Read the input CSV file\n",
    "data = pd.read_csv(input_csv_path, low_memory=False)\n",
    "\n",
    "# Define the length of kmer and sliding window\n",
    "kmer_length = 250\n",
    "sliding_window = 1 \n",
    "\n",
    "def extract_kmers(sequence, kmer_length, sliding_window):\n",
    "    \"\"\"Extract kmers with a specified sliding window from the given sequence.\"\"\"\n",
    "    kmers = []\n",
    "    for start in range(0, len(sequence) - kmer_length + 1, sliding_window):\n",
    "        kmer = sequence[start:start + kmer_length]\n",
    "        kmers.append(kmer)\n",
    "    return kmers\n",
    "\n",
    "# Open the output CSV file for writing\n",
    "with open(output_csv_path, mode='w', newline='') as csv_file:\n",
    "    # Define the fieldnames for the output CSV\n",
    "    fieldnames = data.columns.tolist()\n",
    "    if 'sequence' in fieldnames:\n",
    "        fieldnames.remove('sequence')  # remove 'sequence' to add kmers later\n",
    "    fieldnames.append('sequence')\n",
    "    \n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Process each row in the input data with a progress bar\n",
    "    for _, row in tqdm(data.iterrows(), total=data.shape[0], desc='Processing Rows'):\n",
    "        sequence = row['sequence']\n",
    "        kmers = extract_kmers(sequence, kmer_length, sliding_window)\n",
    "        \n",
    "        # Write each kmer with the associated row data\n",
    "        for kmer in kmers:\n",
    "            row_data = row.to_dict()  # Convert row to dictionary\n",
    "            row_data['sequence'] = kmer\n",
    "            writer.writerow(row_data)\n",
    "\n",
    "print(f\"KMers extracted and written to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90c833-8995-4f5e-bcee-e1df87e6349a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48180b58-8bba-4f66-a0f0-93e70dc055de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.3.0",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
